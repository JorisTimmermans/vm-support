{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTIPLY SAR Data Access and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this Jupyter Notebook is to show how the MULTIPLY platform can be used to retrieve S1 SLC Data from the Data Access Component and how it can be processed into S1 GRD Data using the SAR Pre-Processing functionality.\n",
    "\n",
    "First, let's define working directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vm_support import get_working_dir\n",
    "name = 'm1'\n",
    "\n",
    "# create and/or clear working directory\n",
    "working_dir = get_working_dir(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory is /Data/t_fincke/m1\n"
     ]
    }
   ],
   "source": [
    "print('Working directory is {}'.format(working_dir))\n",
    "s1_slc_directory = '{}/s1_slc'.format(working_dir)\n",
    "s1_grd_directory = '{}/s1_grd'.format(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define start and end times and a region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time_as_string = '2018-05-10'\n",
    "# stop_time_as_string = '2018-05-20'\n",
    "# roi = \"POLYGON((-2.20397502663252 39.09868106889479,-1.9142106223355313 39.09868106889479,\" \\\n",
    "#                  \"-1.9142106223355313 38.94504502508093,-2.20397502663252 38.94504502508093,\" \\\n",
    "#                  \"-2.20397502663252 39.09868106889479))\"\n",
    "start_time_as_string = '2017-06-01'\n",
    "stop_time_as_string = '2017-06-10'\n",
    "roi = 'POLYGON((9.8 53.6,10.2 53.6,10.2 53.4, 9.8 53.4, 9.8 53.6))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SAR Pre-Processing we require a config file. Let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vm_support import create_sar_config_file\n",
    "create_sar_config_file(temp_dir=working_dir, roi=roi, start_time=start_time_as_string, end_time=stop_time_as_string,\n",
    "                       s1_slc_directory=s1_slc_directory, s1_grd_directory=s1_grd_directory)\n",
    "config_file = f'{working_dir}/sar_config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next set up the Data Access Component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Read data store aws_s2\n",
      "INFO:root:Read data store cams\n",
      "INFO:root:Read data store cams_tiff\n",
      "INFO:root:Read data store emulators\n",
      "INFO:root:Read data store wv_emulator\n",
      "INFO:root:Read data store aster_dem\n",
      "INFO:root:Read data store modis_mcd43a1\n",
      "INFO:root:Read data store S2L2\n",
      "INFO:root:Read data store MundiRest\n"
     ]
    }
   ],
   "source": [
    "from multiply_data_access import DataAccessComponent\n",
    "dac = DataAccessComponent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SAR Pre-Processing we need to have 15 products at least: 7 before and 7 after the product in question. However, the SAR Pre-Processing does not count all products as full products: If the products are located close to a border, they are counted as half products. As the determination whether a product is counted as a full or half a product is made by the SAR Pre-Processor, we need it to determine he products that are required. To do so, it might also be necessary to download products.\n",
    "\n",
    "Let's start with determining the actual start date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Data/archive/S1_SLC/2017/05/25/S1A_IW_SLC__1SDV_20170525T170030_20170525T170057_016741_01BCE3_9B0A.zip',\n",
       " '/Data/archive/S1_SLC/2017/05/26/S1B_IW_SLC__1SDV_20170526T054019_20170526T054046_005765_00A1A5_5866.zip',\n",
       " '/Data/archive/S1_SLC/2017/05/26/S1B_IW_SLC__1SDV_20170526T054044_20170526T054111_005765_00A1A5_A40E.zip',\n",
       " '/Data/archive/S1_SLC/2017/05/27/S1A_IW_SLC__1SDV_20170527T053246_20170527T053314_016763_01BD9F_AFBF.zip',\n",
       " '/Data/archive/S1_SLC/2017/05/27/S1A_IW_SLC__1SDV_20170527T053311_20170527T053338_016763_01BD9F_C0E2.zip',\n",
       " '/Data/archive/S1_SLC/2017/05/30/S1A_IW_SLC__1SDV_20170530T170848_20170530T170915_016814_01BF29_4FBD.zip',\n",
       " '/Data/archive/S1_SLC/2017/05/31/S1B_IW_SLC__1SDV_20170531T165946_20170531T170013_005845_00A3F0_956C.zip',\n",
       " '/Data/archive/S1_SLC/2017/06/01/S1A_IW_SLC__1SDV_20170601T054058_20170601T054126_016836_01BFD8_0070.zip',\n",
       " '/Data/archive/S1_SLC/2017/06/01/S1A_IW_SLC__1SDV_20170601T054123_20170601T054150_016836_01BFD8_B122.zip']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "one_day = datetime.timedelta(days=1)\n",
    "start = datetime.datetime.strptime(start_time_as_string, '%Y-%m-%d')\n",
    "before = start\n",
    "before -= one_day\n",
    "before -= one_day\n",
    "before -= one_day\n",
    "before -= one_day\n",
    "before -= one_day\n",
    "before -= one_day\n",
    "before -= one_day\n",
    "before_date = datetime.datetime.strftime(before, '%Y-%m-%d')\n",
    "data_urls_before = dac.get_data_urls(roi, before_date, start_time_as_string, 'S1_SLC')\n",
    "# before_date\n",
    "data_urls_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 3\n",
      "Number of found files containing area of interest: 3\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n",
      "Number of found files for year 2017: 4\n",
      "Number of found files containing area of interest: 4\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n",
      "Number of found files for year 2017: 4\n",
      "Number of found files containing area of interest: 4\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n",
      "Number of found files for year 2017: 4\n",
      "Number of found files containing area of interest: 4\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n",
      "Number of found files for year 2017: 6\n",
      "Number of found files containing area of interest: 6\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 4\n",
      "Number of found files for year 2017: 8\n",
      "Number of found files containing area of interest: 8\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 6\n",
      "Number of found files for year 2017: 9\n",
      "Number of found files containing area of interest: 9\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading S1B_IW_SLC__1SDV_20170524T170804_20170524T170831_005743_00A0F5_841A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1B_IW_SLC__1SDV_20170524T170804_20170524T170831_005743_00A0F5_841A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Set start date for collecting S1 SLC products to 2017-05-24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files containing area of interest: 10\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 6\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "from multiply_orchestration import create_sym_links\n",
    "from sar_pre_processing import SARPreProcessor\n",
    "one_day = datetime.timedelta(days=1)\n",
    "\n",
    "before_sar_dir = f'{s1_slc_directory}/before'\n",
    "if not os.path.exists(before_sar_dir):\n",
    "    os.makedirs(before_sar_dir)\n",
    "\n",
    "start = datetime.datetime.strptime(start_time_as_string, '%Y-%m-%d')\n",
    "before = start\n",
    "num_before = 0\n",
    "while num_before < 7:\n",
    "    before -= one_day\n",
    "    before_date = datetime.datetime.strftime(before, '%Y-%m-%d')\n",
    "    data_urls_before = dac.get_data_urls(roi, before_date, start_time_as_string, 'S1_SLC')\n",
    "    create_sym_links(data_urls_before, before_sar_dir)\n",
    "    processor = SARPreProcessor(config=config_file, input=before_sar_dir, output=before_sar_dir)\n",
    "    list = processor.create_processing_file_list()\n",
    "    num_before = len(list[0]) + (len(list[1]) / 2.)\n",
    "logging.info(f'Set start date for collecting S1 SLC products to {before_date}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the actual end date. Take care not to set it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading S1A_IW_SLC__1SDV_20170611T170848_20170611T170915_016989_01C495_4CDC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1A_IW_SLC__1SDV_20170611T170848_20170611T170915_016989_01C495_4CDC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 1\n",
      "Number of found files containing area of interest: 1\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading S1B_IW_SLC__1SDV_20170612T165947_20170612T170014_006020_00A90D_02A0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1B_IW_SLC__1SDV_20170612T165947_20170612T170014_006020_00A90D_02A0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 2\n",
      "Number of found files containing area of interest: 2\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading S1A_IW_SLC__1SDV_20170613T054059_20170613T054126_017011_01C547_62FA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1A_IW_SLC__1SDV_20170613T054059_20170613T054126_017011_01C547_62FA\n",
      "INFO:root:Downloading S1A_IW_SLC__1SDV_20170613T054124_20170613T054151_017011_01C547_B0DA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1A_IW_SLC__1SDV_20170613T054124_20170613T054151_017011_01C547_B0DA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 4\n",
      "Number of found files containing area of interest: 4\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading S1B_IW_SLC__1SDV_20170614T053228_20170614T053255_006042_00A9BE_DBFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1B_IW_SLC__1SDV_20170614T053228_20170614T053255_006042_00A9BE_DBFF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 5\n",
      "Number of found files containing area of interest: 5\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n",
      "Number of found files for year 2017: 5\n",
      "Number of found files containing area of interest: 5\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n",
      "Number of found files for year 2017: 5\n",
      "Number of found files containing area of interest: 5\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading S1B_IW_SLC__1SDV_20170617T170806_20170617T170833_006093_00AB35_719A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1B_IW_SLC__1SDV_20170617T170806_20170617T170833_006093_00AB35_719A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 6\n",
      "Number of found files containing area of interest: 6\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading S1A_IW_SLC__1SDV_20170618T170032_20170618T170059_017091_01C7BC_02D2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1A_IW_SLC__1SDV_20170618T170032_20170618T170059_017091_01C7BC_02D2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 7\n",
      "Number of found files containing area of interest: 7\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading S1B_IW_SLC__1SDV_20170619T054034_20170619T054101_006115_00ABDC_1FDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1B_IW_SLC__1SDV_20170619T054034_20170619T054101_006115_00ABDC_1FDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Set end date for collecting S1 SLC products to 2017-06-19.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files containing area of interest: 8\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 2\n"
     ]
    }
   ],
   "source": [
    "after_sar_dir = f'{s1_slc_directory}/after'\n",
    "if not os.path.exists(after_sar_dir):\n",
    "    os.makedirs(after_sar_dir)\n",
    "\n",
    "end = datetime.datetime.strptime(stop_time_as_string, '%Y-%m-%d')\n",
    "after = end\n",
    "num_after = 0\n",
    "while num_after < 7 and after < datetime.datetime.today():\n",
    "    after += one_day\n",
    "    after_date = datetime.datetime.strftime(after, '%Y-%m-%d')\n",
    "    data_urls_after = dac.get_data_urls(roi, stop_time_as_string, after_date, 'S1_SLC')\n",
    "    create_sym_links(data_urls_after, after_sar_dir)\n",
    "    processor = SARPreProcessor(config=config_file, input=after_sar_dir, output=after_sar_dir)\n",
    "    list = processor.create_processing_file_list()\n",
    "    num_after = len(list[0]) + (len(list[1]) / 2.)\n",
    "logging.info(f'Set end date for collecting S1 SLC products to {after_date}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created extra directories for collecting the products. Let's clean up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(before_sar_dir)\n",
    "shutil.rmtree(after_sar_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are finally set to collect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading S1B_IW_SLC__1SDV_20170602T053227_20170602T053254_005867_00A499_9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1B_IW_SLC__1SDV_20170602T053227_20170602T053254_005867_00A499_9917\n",
      "INFO:root:Downloading S1B_IW_SLC__1SDV_20170605T170805_20170605T170832_005918_00A60E_9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1B_IW_SLC__1SDV_20170605T170805_20170605T170832_005918_00A60E_9818\n",
      "INFO:root:Downloading S1A_IW_SLC__1SDV_20170606T170031_20170606T170058_016916_01C25A_5E28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1A_IW_SLC__1SDV_20170606T170031_20170606T170058_016916_01C25A_5E28\n",
      "INFO:root:Downloading S1B_IW_SLC__1SDV_20170607T054033_20170607T054101_005940_00A6B7_41C0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1B_IW_SLC__1SDV_20170607T054033_20170607T054101_005940_00A6B7_41C0\n",
      "INFO:root:Downloading S1A_IW_SLC__1SDV_20170608T053301_20170608T053328_016938_01C30F_C92D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloaded S1A_IW_SLC__1SDV_20170608T053301_20170608T053328_016938_01C30F_C92D\n"
     ]
    }
   ],
   "source": [
    "sar_data_urls = dac.get_data_urls(roi, before_date, after_date, 'S1_SLC')\n",
    "create_sym_links(sar_data_urls, s1_slc_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been collected, we can run the actual SAR Pre-Processing. The Processing consists of three steps. The first two steps create one output product for one input product, while the third step merges information from multiple products. We can run steps 1 and 2 safely now on all the input folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files for year 2017: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Start Pre-processing step 1\n",
      "INFO:root:normalisation angle not specified, default value of 35 is used for processing\n",
      "INFO:root:Scene 1 of 15\n",
      "INFO:root:Process S1A_IW_SLC__1SDV_20170525T170030_20170525T170057_016741_01BCE3_9B0A.zip with SNAP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of found files containing area of interest: 23\n",
      "Number of found files that were double processed: 0.0\n",
      "Number of found files with border issues: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:0\n",
      "INFO:root:Scene 2 of 15\n",
      "INFO:root:Process S1A_IW_SLC__1SDV_20170530T170848_20170530T170915_016814_01BF29_4FBD.zip with SNAP.\n"
     ]
    }
   ],
   "source": [
    "processor = SARPreProcessor(config=config_file, input=s1_slc_directory, output=s1_grd_directory)\n",
    "processor.create_processing_file_list()\n",
    "logging.info('Start Pre-processing step 1')\n",
    "processor.pre_process_step1()\n",
    "logging.info('Finished Pre-processing step 1')\n",
    "logging.info('Start Pre-processing step 2')\n",
    "processor.pre_process_step2()\n",
    "logging.info('Finished Pre-processing step 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 needs to be performed for each product separately. To do this, we need to make sure we hand in the correct products only. The output of the second step is located in an intermediate folder. First, we collect all these files and sort them temporally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_step2_dir = f'{s1_grd_dir}/step2'\n",
    "input_files = glob.glob(f'{output_step2_dir}/*.dim')\n",
    "input_file_dict = {}\n",
    "for input_file in input_files:\n",
    "    input_file_dict[input_file[-68:]] = input_file\n",
    "sorted_input_file_dict = sorted(input_file_dict)\n",
    "sorted_input_files = []\n",
    "for sorted_input_file in sorted_input_file_dict:\n",
    "    sorted_input_files.append(input_file_dict[sorted_input_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the thrird step of the SAR Pre-Processing for every product for which there are at least 7 products before and 7 products after it available. For this, it is necessary to first create the file list, then to remove all files from it that shall not be considered during this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for end in range(14, len(input_files)):\n",
    "    file_list = processor.create_processing_file_list()\n",
    "    start = end-14\n",
    "    sub_list = sorted_input_files[start:end]\n",
    "    for i, list in enumerate(file_list):\n",
    "        for file in list:\n",
    "            processed_name = file.replace('.zip', '_GC_RC_No_Su_Co.dim')\n",
    "            processed_name = processed_name.replace(s1_slc_directory, output_step2_dir)\n",
    "            if processed_name not in sub_list:\n",
    "                list.remove(file)\n",
    "                logging.info(f'Removing file {file}')\n",
    "    processor.set_file_list(file_list)\n",
    "    logging.info(f'Start Pre-processing step 3, run {start}')\n",
    "    processor.pre_process_step3()\n",
    "    logging.info(f'Finished Pre-processing step 3, run {start}')\n",
    "    files = os.listdir(output_step3_dir)\n",
    "    for file in files:\n",
    "        shutil.move(os.path.join(output_step3_dir, file), output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
